{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Linear Regression Coefficients Variability\n",
    "This notebook evaluates the variability of the coefficients of the linear regression models provided by statsmodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# the dataset for the demo\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the California House price data from Scikit-learn\n",
    "X, y = fetch_california_housing(return_X_y=True, as_frame=True)\n",
    "X = X.drop(columns = [\"Latitude\", \"Longitude\"])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = None, None, None, None\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0,\n",
    ")\n",
    "\n",
    "# Scale data\n",
    "scaler = MinMaxScaler().set_output(transform=\"pandas\").fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_test shape: ', y_test.shape)\n",
    "print()\n",
    "\n",
    "print('5 first rows in X_train:')\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Train a Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our model needs an intercept so we add a column of 1s:\n",
    "\n",
    "X_train = sm.add_constant(X_train)\n",
    "X_test = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "\n",
    "linreg = sm.OLS(y_train, X_train)\n",
    "results = linreg.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Coefficients direction (sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients value\n",
    "\n",
    "s = pd.Series(\n",
    "    results.params,\n",
    "    index=X_train.columns,\n",
    ")\n",
    "\n",
    "s.plot.bar(yerr=results.bse)\n",
    "plt.ylabel(\"Coefficients' value\")\n",
    "plt.title(\"Coefficients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We see that the variability of the coefficients is different.\n",
    "\n",
    "We also see that the variables `AveRooms` and `AveBdrms` have opposite direction. We'd expect, intuitively that they have the same direction. And we also expect these variables to be highly correlated.\n",
    "\n",
    "Note that the errors estimated by statsmodels are smaller than those observed with cross-validation in the previously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Coefficient absolute value - feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean coefficient and std\n",
    "\n",
    "s = pd.Series(\n",
    "    np.abs(results.params),\n",
    "    index=X_train.columns,\n",
    ")\n",
    "\n",
    "s.plot.bar(yerr=results.bse)\n",
    "plt.ylabel(\"Absolute coefficient value\")\n",
    "plt.title(\"Absolute coefficient value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "From the previous plot, we'd expect the variables `AveRooms` and `AveBdrms` to be the ones with the highest importance. However, the coefficients for those variables also show more variability, or a bigger error. Then, we can trust them less."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate and plot t\n",
    "\n",
    "s = pd.Series(\n",
    "    np.abs(results.tvalues),\n",
    "    index=X_train.columns,\n",
    ")\n",
    "\n",
    "s.plot.bar()\n",
    "plt.ylabel(\"t\")\n",
    "plt.title(\"t\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "After correcting the coefficient by its error, we see that `MedInc` is a more robust predictor of house price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
